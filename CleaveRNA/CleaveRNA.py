import argparse
import os
import sys
import traceback
from Feature import main as feature_main
import pandas as pd
import numpy as np
import subprocess

def create_cfg_file():
    """Generates the parameters.cfg file with predefined settings."""
    cfg_content = """mode=M
model=X
energy=V
temperature=37
acc=C
accW=150
accL=100
seedBP=5
outSep=,
"""
    with open("parameters.cfg", "w") as cfg_file:
        cfg_file.write(cfg_content)
    print("Configuration file 'parameters.cfg' created.")

def report_file_status(file_path, description):
    if os.path.exists(file_path):
        print(f"Success: {description} generated successfully at {file_path}.")
    else:
        print(f"Error: {description} was not generated.")

def train(args):
    # Ensure Feature.py is executed to generate the required file
    print("Running Feature.py to generate 'all_generated_merged_num.csv'...")
    # Convert the list of targets to a comma-separated string
    targets_arg = ','.join(args.targets)
    feature_command = f"python3 Feature.py --targets {targets_arg} --params {args.params} --feature_mode {args.feature_mode}"
    try:
        subprocess.run(feature_command, shell=True, check=True, cwd=os.getcwd())
        print("Feature.pyI executed successfully.")
    except subprocess.CalledProcessError as e:
        print(f"Error: Feature.py execution failed with error: {e}")
        sys.exit(1)

    # Check if 'all_generated_merged_num.csv' exists after running Feature.py
    if not os.path.exists("all_generated_merged_num.csv"):
        print("Error: 'all_generated_merged_num.csv' was not generated by Feature.py.")
        sys.exit(1)

    if args.default_train_file:
        model_name = args.default_train_file

        # File paths
        default_merged_file = f"{model_name}_default_merged_num.csv"
        target_file = f"{model_name}_target.csv"

        if not os.path.exists(default_merged_file) or not os.path.exists(target_file):
            print(f"Error: Required files '{default_merged_file}' or '{target_file}' do not exist.")
            sys.exit(1)

        # Calculate mean and std for default_merged_file
        df_default = pd.read_csv(default_merged_file)
        mean_std = df_default.describe().loc[['mean', 'std']]
        mean_std_file = f"{model_name}_default_train_statistics.csv"
        mean_std.to_csv(mean_std_file)
        report_file_status(mean_std_file, "Default train statistics")

        # Standardize numerical columns while keeping the 'id2' column
        df_standardized = df_default.copy()
        for column in df_standardized.columns:
            if column != 'id2':
                df_standardized[column] = (df_standardized[column] - mean_std.loc['mean', column]) / mean_std.loc['std', column]
        standardized_file = f"{model_name}_standardized_default_train.csv"
        df_standardized.to_csv(standardized_file, index=False)
        report_file_status(standardized_file, "Standardized default train")

        # Balance target file
        df_target = pd.read_csv(target_file)
        np.random.seed(89273554)
        df_balanced = df_target.groupby('Y', group_keys=False).apply(lambda x: x.sample(df_target['Y'].value_counts().min()))
        balanced_file = f"{model_name}_balanced_target.csv"
        df_balanced.to_csv(balanced_file, index=False)
        report_file_status(balanced_file, "Balanced target")

        df_non_balanced = df_target[~df_target.index.isin(df_balanced.index)]
        non_balanced_file = f"{model_name}_non_balanced_target.csv"
        df_non_balanced.to_csv(non_balanced_file, index=False)
        report_file_status(non_balanced_file, "Non-balanced target")

        # Merge standardized_default_train with balanced_target
        df_merged_train = pd.merge(df_standardized, df_balanced, on='id2')
        merged_train_file = f"{model_name}_default_ML_train.csv"
        df_merged_train.to_csv(merged_train_file, index=False)
        report_file_status(merged_train_file, "Default ML train")

        # Merge standardized_default_train with non_balanced_target
        df_merged_test = pd.merge(df_standardized, df_non_balanced, on='id2')
        merged_test_file = f"{model_name}_default_ML_test.csv"
        df_merged_test.to_csv(merged_test_file, index=False)
        report_file_status(merged_test_file, "Default ML test")

        # Extract feature sets from default_ML_train
        feature_set_1 = ['E_1', 'Pu1_1', 'E_hybrid_1', 'seedNumber_1', 'seedEbest_1', 'seedNumber_3', 'E_diff_12', 'pumin1_4u', 'pumin1_4d', 'pumin5_8d']
        feature_set_2 = ['E_1', 'Pu1_1', 'Pu2_1', 'E_hybrid_1', 'seedEbest_1', 'seedNumber_3', 'pumin1_4u', 'pumin1_4d', 'pumin5_8d']

        df_train = pd.read_csv(merged_train_file)
        feature_set_1_file = f"{model_name}_default_ML_train_feature_set_1.csv"
        df_train[feature_set_1].to_csv(feature_set_1_file, index=False)
        report_file_status(feature_set_1_file, "Default ML train feature set 1")

        feature_set_2_file = f"{model_name}_default_ML_train_feature_set_2.csv"
        df_train[feature_set_2].to_csv(feature_set_2_file, index=False)
        report_file_status(feature_set_2_file, "Default ML train feature set 2")

        # Ensure proper standardization of columns in all_generated_merged_num.csv using HPBC_default_train_statistics.csv
        mean_std_file = "HPBC_default_train_statistics.csv"
        mean_std = pd.read_csv(mean_std_file, index_col=0)
        df_generated = pd.read_csv("all_generated_merged_num.csv")
        df_standardized_generated = df_generated.copy()

        # Standardize only columns present in mean_std
        for column in mean_std.columns:
            if column in df_standardized_generated.columns:
                df_standardized_generated[column] = (df_standardized_generated[column] - mean_std.loc['mean', column]) / mean_std.loc['std', column]

        # Retain id2 column and standardized columns
        df_standardized_generated = df_standardized_generated[['id2'] + list(mean_std.columns)]
        standardized_generated_file = "standardized_all_generated_merged_num.csv"
        df_standardized_generated.to_csv(standardized_generated_file, index=False)
        report_file_status(standardized_generated_file, "Standardized generated merged num")

        # Extract feature sets from standardized_generated_merged_num
        generated_feature_set_1_file = "generated_ML_test_feature_set_1.csv"
        df_standardized_generated[feature_set_1].to_csv(generated_feature_set_1_file, index=False)
        report_file_status(generated_feature_set_1_file, "Generated ML test feature set 1")

        generated_feature_set_2_file = "generated_ML_test_feature_set_2.csv"
        df_standardized_generated[feature_set_2].to_csv(generated_feature_set_2_file, index=False)
        report_file_status(generated_feature_set_2_file, "Generated ML test feature set 2")

    elif args.user_train_file:
        model_name = args.user_train_file

        # File paths
        target_file = f"{model_name}_target.csv"

        # Validate that the required target file exists
        if not os.path.exists(target_file):
            print(f"Error: Required file '{target_file}' does not exist.")
            sys.exit(1)

        # Calculate mean and std for all_generated_merged_num.csv
        df_generated = pd.read_csv("all_generated_merged_num.csv")
        mean_std = df_generated.describe().loc[['mean', 'std']]
        mean_std_file = f"{model_name}_user_train_statistics.csv"
        mean_std.to_csv(mean_std_file)
        report_file_status(mean_std_file, "User train statistics")

        # Standardize numerical columns in all_generated_merged_num.csv
        df_standardized = df_generated.copy()
        for column in df_standardized.columns:
            if column != 'id2':
                df_standardized[column] = (df_standardized[column] - mean_std.loc['mean', column]) / mean_std.loc['std', column]

        # Retain id2 column and save standardized data
        df_standardized = df_standardized[['id2'] + [col for col in df_standardized.columns if col != 'id2']]
        standardized_file = f"{model_name}_standardized_user_train.csv"
        df_standardized.to_csv(standardized_file, index=False)
        report_file_status(standardized_file, "Standardized user train")

        # Balance target file
        df_target = pd.read_csv(target_file)
        np.random.seed(89273554)
        df_balanced = df_target.groupby('Y', group_keys=False).apply(lambda x: x.sample(df_target['Y'].value_counts().min()))
        balanced_file = f"{model_name}_balanced_target.csv"
        df_balanced.to_csv(balanced_file, index=False)
        report_file_status(balanced_file, "Balanced target")

        df_non_balanced = df_target[~df_target.index.isin(df_balanced.index)]
        non_balanced_file = f"{model_name}_non_balanced_target.csv"
        df_non_balanced.to_csv(non_balanced_file, index=False)
        report_file_status(non_balanced_file, "Non-balanced target")

        # Merge standardized_user_train with balanced_target
        df_merged_train = pd.merge(df_standardized, df_balanced, on='id2')
        merged_train_file = f"{model_name}_user_ML_train.csv"
        df_merged_train.to_csv(merged_train_file, index=False)
        report_file_status(merged_train_file, "User ML train")

        # Merge standardized_user_train with non_balanced_target
        df_merged_test = pd.merge(df_standardized, df_non_balanced, on='id2')
        merged_test_file = f"{model_name}_user_ML_test.csv"
        df_merged_test.to_csv(merged_test_file, index=False)
        report_file_status(merged_test_file, "User ML test")

        # Extract feature sets from user_ML_train
        feature_set_1 = ['E_1', 'Pu1_1', 'E_hybrid_1', 'seedNumber_1', 'seedEbest_1', 'seedNumber_3', 'E_diff_12', 'pumin1_4u', 'pumin1_4d', 'pumin5_8d']
        feature_set_2 = ['E_1', 'Pu1_1', 'Pu2_1', 'E_hybrid_1', 'seedEbest_1', 'seedNumber_3', 'pumin1_4u', 'pumin1_4d', 'pumin5_8d']

        # Ensure df_train is initialized before use
        df_train = pd.read_csv(merged_train_file)

        # Extract feature sets from user_ML_train and include 'Y' column
        feature_set_1_with_y = feature_set_1 + ['Y']
        feature_set_2_with_y = feature_set_2 + ['Y']

        feature_set_1_file = f"{model_name}_user_ML_train_feature_set_1.csv"
        df_train[feature_set_1_with_y].to_csv(feature_set_1_file, index=False)
        report_file_status(feature_set_1_file, "User ML train feature set 1 with Y")

        feature_set_2_file = f"{model_name}_user_ML_train_feature_set_2.csv"
        df_train[feature_set_2_with_y].to_csv(feature_set_2_file, index=False)
        report_file_status(feature_set_2_file, "User ML train feature set 2 with Y")

        # Standardize user_ML_test.csv
        df_test = pd.read_csv(merged_test_file)
        df_test_standardized = (df_test - mean_std.loc['mean']) / mean_std.loc['std']
        standardized_test_file = f"{model_name}_standardized_user_ML_test.csv"
        df_test_standardized.to_csv(standardized_test_file, index=False)
        report_file_status(standardized_test_file, "Standardized user ML test")

        # Extract feature set 1 from user_ML_test.csv
        feature_set_1 = ['E_1', 'Pu1_1', 'E_hybrid_1', 'seedNumber_1', 'seedEbest_1', 'seedNumber_3', 'E_diff_12', 'pumin1_4u', 'pumin1_4d', 'pumin5_8d']
        feature_set_1_file = f"{model_name}_user_ML_test_feature_set_1.csv"
        df_test = pd.read_csv(merged_test_file)
        df_test[feature_set_1].to_csv(feature_set_1_file, index=False)
        report_file_status(feature_set_1_file, "User ML test feature set 1")

        # Extract feature set 2 from standardized_user_ML_test.csv
        feature_set_2 = ['E_1', 'Pu1_1', 'Pu2_1', 'E_hybrid_1', 'seedEbest_1', 'seedNumber_3', 'pumin1_4u', 'pumin1_4d', 'pumin5_8d']
        feature_set_2_file = f"{model_name}_user_ML_test_feature_set_2.csv"
        df_test_standardized = pd.read_csv(standardized_test_file)
        df_test_standardized[feature_set_2].to_csv(feature_set_2_file, index=False)
        report_file_status(feature_set_2_file, "User ML test feature set 2")

    else:
        print("Error: Either --default_train_file or --user_train_file must be provided.")
        sys.exit(1)

def main():
    try:
        parser = argparse.ArgumentParser()
        parser.add_argument('--targets', required=True, nargs='+', help="Path to one or more FASTA files")
        parser.add_argument('--params', required=True, help="Path to the CSV file containing LA, RA, CS, temperature, and core")
        parser.add_argument('--feature_mode', required=True, choices=['default', 'target_screen', 'target_check', 'specific_target'], help="Mode of operation")
        parser.add_argument('--specific_csv', help="CSV file for specific_target mode")
        parser.add_argument('--default_train_file', help="Prefix of the model name for default training")
        parser.add_argument('--user_train_file', help="Path to user-provided training file")
        args = parser.parse_args()

        # Debugging: Print parsed arguments
        print("Parsed arguments:", args)

        # Validate each target file in the list
        for target in args.targets:
            if not os.path.exists(target):
                print(f"Error: Target file '{target}' does not exist.")
                sys.exit(1)

        if not os.path.exists(args.params):
            print(f"Error: Parameters file '{args.params}' does not exist.")
            sys.exit(1)

        if args.feature_mode == 'specific_target' and args.specific_csv and not os.path.exists(args.specific_csv):
            print(f"Error: Specific CSV file '{args.specific_csv}' does not exist.")
            sys.exit(1)

        # Debugging: Print mode-specific logic
        print(f"Running in mode: {args.feature_mode}")
        if args.specific_csv:
            print(f"Using specific CSV: {args.specific_csv}")

        # Create parameters.cfg if it doesn't exist
        if not os.path.exists("parameters.cfg"):
            create_cfg_file()

        # Execute Feature processing, removing the placeholder print
        train(args)

    except Exception as e:
        print("An error occurred:", str(e))
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()